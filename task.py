import asyncio
import os
from dotenv import load_dotenv

from browser_use import Agent, Controller, ActionResult
from langchain_google_genai import ChatGoogleGenerativeAI   # Gemini LLM

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()                         # .env íŒŒì¼ì— GEMINI_API_KEY ë“±ì„ ë„£ì–´ ë‘ì„¸ìš”
GEMINI_MODEL = "gemini-2.0-flash" # í•„ìš” ì‹œ ë‹¤ë¥¸ ë²„ì „ìœ¼ë¡œ êµì²´

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ì‚¬ìš©ì-ì…ë ¥ìš© ì»¤ìŠ¤í…€ ì•¡ì…˜ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
controller = Controller()


@controller.action("Ask user for information")
def ask_user(question: str) -> str:
    answer = input(f"\n{question}\nì…ë ¥ âœ ")
    # ğŸ‘‡ ê¼­ include_in_memory=Trueë¡œ ë°˜í™˜
    return ActionResult(
        extracted_content=answer,
        include_in_memory=True  # â† ì´ ì¤„ì´ ìˆì–´ì•¼ LLMì´ ê¸°ì–µí•©ë‹ˆë‹¤
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. LLM ë° Agent ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
llm = ChatGoogleGenerativeAI(
    model=GEMINI_MODEL,
    temperature=0.0,
)

def build_agent(task: str) -> Agent:
    """
    ì›í•˜ëŠ” ì‘ì—…(task) ë¬¸ìì—´ë§Œ ë„˜ê¸°ë©´
    Ask-user ì•¡ì…˜ì´ ë‚´ì¥ëœ Agent ì¸ìŠ¤í„´ìŠ¤ë¥¼ ëŒë ¤ì¤€ë‹¤.
    """
    return Agent(
        task=task,
        llm=llm,
        controller=controller,
        enable_memory=True,
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ì‹¤í–‰ ì˜ˆì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def main():
    with open("script_kr.md", "r", encoding="utf-8") as f:
        task = f.read()

    agent = build_agent(task)
    await agent.run(max_steps=50)

if __name__ == "__main__":
    asyncio.run(main())
